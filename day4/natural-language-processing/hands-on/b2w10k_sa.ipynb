{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "b2w10k-sa.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqRpgItoCjDb",
        "colab_type": "text"
      },
      "source": [
        "# Analise de Sentimento\n",
        "\n",
        "### Baixando o Córpus\n",
        "\n",
        "Existe um córpus livre de avaliações disponibilizados pela empresa B2W/americanas.com,\n",
        "que pode ser baixado a partir do seguinte \n",
        "[endereço do github](https://github.com/b2wdigital/b2w-reviews01)\n",
        "\n",
        "O córpus é disponibilizado em dois formatos, Ou com um  banco de dados sqlite3  ou como uma planilha no formato csv (comma separated values),  que nada mais é do que uma lista separada por vírgulas de todos os itens,   uma entrada por linha.  \n",
        "\n",
        "Neste tutorial iremos usar o formato csv.  \n",
        "A planilha possui 132.374  entradas e foi disponibilizada ao público em 2019.   \n",
        "Para esse exercício sugerimos uma versão reduzida deste corpus com 10 mil entradas,\n",
        "no arquivo `data/b2w-10k.csv`. \n",
        "\n",
        "Vamos experimentar com este arquivo.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McpFPAo_EY4b",
        "colab_type": "code",
        "outputId": "25058ad8-ceed-46c4-c1dd-7db599070e7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!python -m spacy download pt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pt_core_news_sm==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.1.0/pt_core_news_sm-2.1.0.tar.gz (12.8MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 620kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pt-core-news-sm\n",
            "  Building wheel for pt-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pt-core-news-sm: filename=pt_core_news_sm-2.1.0-cp36-none-any.whl size=12843677 sha256=c0a066094e8910e4dc7ca9836df9fa4f13f211f52bdd5d5f7960e28d2e2ea2ef\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-g6kb5iul/wheels/a3/8f/c1/f036e3a7f1aa44fb06a534c6c4b1c2b773f101fdb1f163c08c\n",
            "Successfully built pt-core-news-sm\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/pt_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/pt\n",
            "You can now load the model via spacy.load('pt')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oBZ_RpUD6pw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vl9DpxXDpLd",
        "colab_type": "code",
        "outputId": "cc7dffb2-723d-4709-fd8d-46f4d5c9bea9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!wget -c https://github.com/advinstai/dsml-school2019/raw/master/day4/data/b2w-10k.csv -O data/b2w-10k.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-19 19:01:56--  https://github.com/advinstai/dsml-school2019/raw/master/day4/data/b2w-10k.csv\n",
            "Resolving github.com (github.com)... 140.82.113.3\n",
            "Connecting to github.com (github.com)|140.82.113.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/advinstai/dsml-school2019/master/day4/data/b2w-10k.csv [following]\n",
            "--2019-12-19 19:01:57--  https://raw.githubusercontent.com/advinstai/dsml-school2019/master/day4/data/b2w-10k.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4013451 (3.8M) [text/plain]\n",
            "Saving to: ‘data/b2w-10k.csv’\n",
            "\n",
            "\rdata/b2w-10k.csv      0%[                    ]       0  --.-KB/s               \rdata/b2w-10k.csv    100%[===================>]   3.83M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-12-19 19:01:57 (79.7 MB/s) - ‘data/b2w-10k.csv’ saved [4013451/4013451]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yihnDVCQCjDh",
        "colab_type": "code",
        "outputId": "8005069a-93d5-4d0c-9762-06809b4b8fdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "b2wCorpus = pd.read_csv(\"data/b2w-10k.csv\")\n",
        "b2wCorpus.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>submission_date</th>\n",
              "      <th>reviewer_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>product_name</th>\n",
              "      <th>product_brand</th>\n",
              "      <th>site_category_lv1</th>\n",
              "      <th>site_category_lv2</th>\n",
              "      <th>review_title</th>\n",
              "      <th>overall_rating</th>\n",
              "      <th>recommend_to_a_friend</th>\n",
              "      <th>review_text</th>\n",
              "      <th>reviewer_birth_year</th>\n",
              "      <th>reviewer_gender</th>\n",
              "      <th>reviewer_state</th>\n",
              "      <th>Unnamed: 14</th>\n",
              "      <th>Unnamed: 15</th>\n",
              "      <th>Unnamed: 16</th>\n",
              "      <th>Unnamed: 17</th>\n",
              "      <th>Unnamed: 18</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2018-01-01 00:11:28</td>\n",
              "      <td>d0fb1ca69422530334178f5c8624aa7a99da47907c44de...</td>\n",
              "      <td>132532965</td>\n",
              "      <td>Notebook Asus Vivobook Max X541NA-GO472T Intel...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Informática</td>\n",
              "      <td>Notebook</td>\n",
              "      <td>Bom</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
              "      <td>1958</td>\n",
              "      <td>F</td>\n",
              "      <td>RJ</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2018-01-01 00:13:48</td>\n",
              "      <td>014d6dc5a10aed1ff1e6f349fb2b059a2d3de511c7538a...</td>\n",
              "      <td>22562178</td>\n",
              "      <td>Copo Acrílico Com Canudo 500ml Rocie</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Utilidades Domésticas</td>\n",
              "      <td>Copos, Taças e Canecas</td>\n",
              "      <td>Preço imbatível, ótima qualidade</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
              "      <td>1996</td>\n",
              "      <td>M</td>\n",
              "      <td>SC</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2018-01-01 00:26:02</td>\n",
              "      <td>44f2c8edd93471926fff601274b8b2b5c4824e386ae4f2...</td>\n",
              "      <td>113022329</td>\n",
              "      <td>Panela de Pressão Elétrica Philips Walita Dail...</td>\n",
              "      <td>philips walita</td>\n",
              "      <td>Eletroportáteis</td>\n",
              "      <td>Panela Elétrica</td>\n",
              "      <td>ATENDE TODAS AS EXPECTATIVA.</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
              "      <td>1984</td>\n",
              "      <td>M</td>\n",
              "      <td>SP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2018-01-01 00:35:54</td>\n",
              "      <td>ce741665c1764ab2d77539e18d0e4f66dde6213c9f0863...</td>\n",
              "      <td>113851581</td>\n",
              "      <td>Betoneira Columbus - Roma Brinquedos</td>\n",
              "      <td>roma jensen</td>\n",
              "      <td>Brinquedos</td>\n",
              "      <td>Veículos de Brinquedo</td>\n",
              "      <td>presente mais que desejado</td>\n",
              "      <td>4</td>\n",
              "      <td>Yes</td>\n",
              "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
              "      <td>1985</td>\n",
              "      <td>F</td>\n",
              "      <td>SP</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2018-01-01 01:00:28</td>\n",
              "      <td>7d7b6b18dda804a897359276cef0ca252f9932bf4b5c8e...</td>\n",
              "      <td>131788803</td>\n",
              "      <td>Smart TV LED 43\" LG 43UJ6525 Ultra HD 4K com C...</td>\n",
              "      <td>lg</td>\n",
              "      <td>TV e Home Theater</td>\n",
              "      <td>TV</td>\n",
              "      <td>Sem duvidas, excelente</td>\n",
              "      <td>5</td>\n",
              "      <td>Yes</td>\n",
              "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
              "      <td>1994</td>\n",
              "      <td>M</td>\n",
              "      <td>MG</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       submission_date  ... Unnamed: 18\n",
              "0  2018-01-01 00:11:28  ...         NaN\n",
              "1  2018-01-01 00:13:48  ...         NaN\n",
              "2  2018-01-01 00:26:02  ...         NaN\n",
              "3  2018-01-01 00:35:54  ...         NaN\n",
              "4  2018-01-01 01:00:28  ...         NaN\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n6B0Q9ZCjDo",
        "colab_type": "text"
      },
      "source": [
        "O córpus tem uma série de informações,  mas para esse treinamento iremos usar apenas \n",
        "duas. A coluna de entrada será `review_text`, contendo o texto da avaliação em \n",
        "português brasileiro,  e a coluna de saída será `recommend_to_a_friend`  contendo a\n",
        "recomendação de indicar o produto para um amigo;  a coluna de saída tem apenas dois \n",
        "valores: \"Yes\" ou \"No\".\n",
        "\n",
        "Claramente o arquivo foi preparado para ser usado pela Comunidade Internacional e não apenas para os que falam português.  Vamos preparar uma versão com apenas estas colunas e armazená-la na planilha `data/b2w-10k-short.csv`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdkBlRwuCjDq",
        "colab_type": "code",
        "outputId": "886f39f6-2a4a-4c39-9b88-44bfbf70b689",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "binary= [1 if str == \"Yes\" else 0 for str in b2wCorpus[\"recommend_to_a_friend\"]]\n",
        "textos = list(b2wCorpus[\"review_text\"])\n",
        "\n",
        "data = {'Texto': textos, 'Julgamento':binary}\n",
        "df = pd.DataFrame(data) \n",
        "df.to_csv(\"data/b2w-10k-short.csv\",index=False)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Texto</th>\n",
              "      <th>Julgamento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Estou contente com a compra entrega rápida o ú...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Por apenas R$1994.20,eu consegui comprar esse ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A entrega foi no prazo, as americanas estão de...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Texto  Julgamento\n",
              "0  Estou contente com a compra entrega rápida o ú...           1\n",
              "1  Por apenas R$1994.20,eu consegui comprar esse ...           1\n",
              "2  SUPERA EM AGILIDADE E PRATICIDADE OUTRAS PANEL...           1\n",
              "3  MEU FILHO AMOU! PARECE DE VERDADE COM TANTOS D...           1\n",
              "4  A entrega foi no prazo, as americanas estão de...           1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPxb2bAcCjDx",
        "colab_type": "text"
      },
      "source": [
        "Preparação dos dados\n",
        "\n",
        "Vamos sparar o córpus em 3 partes: treino, validação e teste."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo45c_rWCjDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy  as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "MAIN_CSV  = \"data/b2w-10k-short.csv\"\n",
        "VAL_RATIO = 0.1\n",
        "TRAIN_CSV = \"data/b2w-train-10k-short.csv\"\n",
        "VAL_CSV   = \"data/b2w-val-10k-short.csv\"\n",
        "TEST_CSV  = \"data/b2w-test-10k-short.csv\"\n",
        "\n",
        "df = pd.read_csv(MAIN_CSV)\n",
        "\n",
        "# Enbaralha as linhas da entrada\n",
        "idx = np.arange(df.shape[0])\n",
        "np.random.seed()\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# train: 80%, val: 10%, test: 10%\n",
        "valSize = int(len(idx) * VAL_RATIO)\n",
        "df.iloc[idx[2*valSize:],        0:2].to_csv(TRAIN_CSV,index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
        "df.iloc[idx[:valSize],          0:2].to_csv(VAL_CSV, index=False, quoting=csv.QUOTE_NONNUMERIC)\n",
        "df.iloc[idx[valSize:2*valSize], 0:2].to_csv(TEST_CSV, index=False, quoting=csv.QUOTE_NONNUMERIC)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgwXY0HUCjD1",
        "colab_type": "text"
      },
      "source": [
        "Para tokenizar, usamos expressões regulares do pacote `re` em conjunção com o tokenizador do `spacy`.\n",
        "E para gerar os datasets, usamos a biblioteca `torchtext` e suas classes `Field` e `TabularDataset`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysUudgAYCjD2",
        "colab_type": "code",
        "outputId": "67708372-8e36-431d-d9a8-84c87e8d2555",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import torch\n",
        "import spacy\n",
        "import re\n",
        "from torchtext import data\n",
        "from torchtext import datasets\n",
        "\n",
        "from os import path\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "\n",
        "spacy_pt = spacy.load('pt')\n",
        "def tokenizePT(s):\n",
        "    comment = re.sub(r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(s))\n",
        "    comment = re.sub(r\"[ ]+\", \" \", comment)\n",
        "    comment = re.sub(r\"\\!+\", \"!\", comment)\n",
        "    comment = re.sub(r\"\\,+\", \",\", comment)\n",
        "    comment = re.sub(r\"\\.+\", \".\", comment)\n",
        "    comment = re.sub(r\"\\?+\", \"?\", comment)\n",
        "    return [tok.text for tok in spacy_pt.tokenizer(comment) if tok.text != \" \"]\n",
        "\n",
        "UNK = \"<unk>\"\n",
        "PAD = \"<pad>\"    \n",
        "SOS = \"<s>\"\n",
        "EOS = \"</s>\"\n",
        "LOWER = True\n",
        "MIN_FREQ = 20\n",
        "\n",
        "TEXT  = data.Field(tokenize=tokenizePT, batch_first=True, lower=LOWER, \n",
        "                 include_lengths=True, unk_token=UNK, pad_token=PAD, \n",
        "                 init_token=SOS, eos_token=EOS)\n",
        "LABEL = data.LabelField(dtype=torch.float,use_vocab=False, sequential=False)\n",
        "\n",
        "trainDataset, valDataset, testDataset = data.TabularDataset.splits(\n",
        "            path       = path.dirname( TRAIN_CSV ),\n",
        "            train      = path.basename(TRAIN_CSV), \n",
        "            validation = path.basename(VAL_CSV), \n",
        "            test       = path.basename(TEST_CSV),\n",
        "            format     = 'csv', \n",
        "            skip_header= True,\n",
        "            fields     = [('Texto', TEXT),('Julgamento', LABEL)]\n",
        ")\n",
        "\n",
        "TEXT.build_vocab(trainDataset, valDataset, testDataset, min_freq=MIN_FREQ) \n",
        "print(\"Size vocab: \", len(TEXT.vocab))    \n",
        "print(\"Size datasetS: \", len(trainDataset), len(valDataset), len(testDataset))    \n",
        " \n",
        "for i in range(10):\n",
        "    print(TEXT.vocab.itos[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size vocab:  1135\n",
            "Size datasetS:  8001 999 999\n",
            "<unk>\n",
            "<pad>\n",
            "<s>\n",
            "</s>\n",
            ".\n",
            ",\n",
            "o\n",
            "e\n",
            "a\n",
            "de\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqwXdZdoCjEH",
        "colab_type": "code",
        "outputId": "f0380998-23ea-44cd-dea7-76441e284eba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "for t in trainDataset.Texto:\n",
        "    print(t)\n",
        "    break\n",
        "for j in trainDataset.Julgamento:\n",
        "    print(j)\n",
        "    break\n",
        "for t in valDataset.Texto:\n",
        "    print(t)\n",
        "    break\n",
        "for t in testDataset.Texto:\n",
        "    print(t)\n",
        "    break\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['comprei', 'o', 'console', 'xbox', '360', '4', 'gb', 'controle', 'sem', 'fio', ',', 'faturado', 'em', 'novembro', ',', 'e', 'o', 'jogo', 'comprei', 'depois', 'e', 'chegou', 'primeiro', ',', 'e', 'ele', 'até', 'agora', 'nada,.e', 'ai', 'está', 'esperando', 'o', 'que', '?']\n",
            "0\n",
            "['voltarei', 'a', 'comprar', 'nas', 'americanas', '.indico', '.', 'sempre', 'veio', 'conforme', 'o', 'pedido', '.', 'rápido', 'na', 'entrega.nota', '10']\n",
            "['pedi', ',', 'paguei', ',', 'venceu', 'o', 'prazo', 'da', 'entrega', 'e', 'ainda', 'não', 'recebi', 'o', 'produto', '.', 'na', 'hora', 'da', 'compra', 'informaram', '9', 'dias', 'úteis', ',', 'quando', 'finalizei', 'já', 'passou', 'para', '10', 'dias', 'úteis', '.', 'passou', 'o', 'prazo', 'e', 'só', 'a', 'nota', 'foi', 'emitida', ',', 'nem', 'foi', 'para', 'transporte', 'ainda', '.', 'vou', 'devolver']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXkTzA2PCjEP",
        "colab_type": "text"
      },
      "source": [
        "Agora vamos criar iteradores que irão dividir ir os nossos corpus em lotes do \n",
        "tamanho `BATCH_ SIZE`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdYTLMyKssxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "8-d4LqbkCjER",
        "colab_type": "code",
        "outputId": "4bce220f-f027-4661-eac4-f5b8aef343bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "trainIter, validIter, testIter = data.BucketIterator.splits(\n",
        "    (trainDataset, valDataset, testDataset), \n",
        "    batch_size=BATCH_SIZE, \n",
        "    sort_key=lambda x: len(x.Texto),\n",
        "    sort_within_batch=True,\n",
        "    repeat=False,\n",
        "    device=device)\n",
        "\n",
        "for b in trainIter:\n",
        "    print(b.Texto, b.Julgamento)\n",
        "    break\n",
        "for b in validIter:\n",
        "    print(b.Texto, b.Julgamento)\n",
        "    break\n",
        "for b in testIter:\n",
        "    print(b.Texto, b.Julgamento)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([[   2,   48,  155,    5,  169,    5,   77,  470,    5,  129,  510,  291,\n",
            "            4,    3],\n",
            "        [   2,  658,    9,    0,    4,    0,   14,    0,    5,   11,    0,    0,\n",
            "            4,    3],\n",
            "        [   2,   33,   10,   22,    0,    4,   21,   74,    7,   16,   19,   68,\n",
            "            4,    3],\n",
            "        [   2,   32,   23,  110,  252,    5,   79,    0,  852,  138,  123,  630,\n",
            "            4,    3],\n",
            "        [   2,   10,   32,   38,   15,  161,    7,   50,    6,  184,   72,  354,\n",
            "            4,    3],\n",
            "        [   2,  658,    9,    0,    0,  611,    4,   32,   38,   15,   31,  426,\n",
            "            4,    3],\n",
            "        [   2,   10,    9,   70,   25,    7,   16,   21,   96,   15,   31,    4,\n",
            "           20,    3],\n",
            "        [   2,    0,   14,  459,    9,   10,    9,   25, 1048,    5,   13,   19,\n",
            "          115,    3]], device='cuda:0'), tensor([14, 14, 14, 14, 14, 14, 14, 14], device='cuda:0')) tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "(tensor([[  2,  79,  26, 111,   3],\n",
            "        [  2,  10,   0,   4,   3],\n",
            "        [  2,  79, 252,   4,   3],\n",
            "        [  2, 804,   4,   3,   1],\n",
            "        [  2,   0,   3,   1,   1],\n",
            "        [  2,   0,   3,   1,   1],\n",
            "        [  2,   0,   3,   1,   1],\n",
            "        [  2,   0,   3,   1,   1]], device='cuda:0'), tensor([5, 5, 5, 4, 3, 3, 3, 3], device='cuda:0')) tensor([1., 1., 1., 1., 1., 1., 1., 0.], device='cuda:0')\n",
            "(tensor([[  2,  55,  13, 179, 234,  80,  75,   4,   3],\n",
            "        [  2, 134, 158, 708, 860,   0,   4, 187,   3],\n",
            "        [  2,  37,  10,  94,  92, 269,  20,   3,   1],\n",
            "        [  2,  47,  13,  15,   0,   3,   1,   1,   1],\n",
            "        [  2,  47,  15,  10,   4,   3,   1,   1,   1],\n",
            "        [  2, 600,  19,   4,   3,   1,   1,   1,   1],\n",
            "        [  2,  19,  10,   4,   3,   1,   1,   1,   1],\n",
            "        [  2,  47,   0,   3,   1,   1,   1,   1,   1]], device='cuda:0'), tensor([9, 9, 8, 6, 6, 5, 5, 4], device='cuda:0')) tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AJhBJMQCjEp",
        "colab_type": "text"
      },
      "source": [
        "## Construição do modelo\n",
        "\n",
        "Utilizamos uma arquitetura RNN denominada LSTM (Long Short-Term Memory). Nela o estado oculto pode ser pensado como uma \"memória\" das palavras vistas pelo modelo. As redes LSTMs têm um estado recorrente extra chamado _cell_, que pode ser considerado a \"memória\" do LSTM e pode lembrar informações por várias etapas. As LSTMs também usam vários _gates_, controlam o fluxo de informações para dentro e para fora da memória. Para mais informações, acesse [aqui] (https://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
        "\n",
        "### LSTM bidirecional\n",
        "\n",
        "O conceito por trás de uma RNN bidirecional é simples. Além de ter uma RNN direta processando as palavras na frase da primeiro à última posição, temos uma segunda RNN reversa processando as palavras na frase da **última à primeira**. Numa LSTM bidirecional o estado oculto final retornado, `hidden`, é a concatenação do estado oculto da última palavra da frase da RNN direta com o estado oculto da primeira palavra da sentença da RNN reversa, sendo ambos os estados ocultos finais de suas respectivas RNNs.\n",
        "\n",
        "![](https://i.imgur.com/itmIIgx.png)\n",
        "\n",
        "### RNN de várias camadas\n",
        "\n",
        "RNN multicamada (também chamados de *RNN profunda*) é outro conceito simples. A idéia é que adicionemos RNNs adicionais sobre a RNN padrão inicial, onde cada RNN adicionada é outra *camada*. A saída do estado oculto pela primeira RNN (inferior) no tempo $t$ será a entrada para a RNN acima dela no tempo $t$. A previsão é geralmente feita a partir do estado oculto final da camada final (mais alta). Estes são facilmente combinados com RNNs bidirecionais, onde cada camada extra adiciona um RNN adicional direta e reversa.\n",
        "\n",
        "![](https://i.imgur.com/knsIzeh.png)\n",
        "\n",
        "### Regularização\n",
        "\n",
        "Quanto mais parâmetros você tiver em seu modelo, maior a probabilidade de que você se ajuste demais (tenha um erro baixo de treino, mas alto erro de validação/teste, chamado de _overfitting_). Para combater isso, usamos de regularização. Mais especificamente, usamos um método de regularização chamado *dropout*, o qual funciona aleatoriamente *retirando* (ddando peso 0 a) neurônios durante uma passagem da rede. A probabilidade de que cada neurônio seja eliminado é definida por um hiperparâmetro e cada neurônio com é considerado para o _dropout_ de forma independente. Um modelo com parâmetros eliminados pode ser visto como um modelo \"mais fraco\" (menos parâmetros); as previsões de todos esses modelos \"mais fracos\" (um para cada passagem da rede) são calculadas em conjunto nos parâmetros do modelo. Assim, seu único modelo pode ser pensado como um conjunto de modelos mais fracos, nenhum dos quais é super parametrizado e, portanto, não deve estar super ajustado.\n",
        "\n",
        "### Detalhes da implementação\n",
        "\n",
        "Para usar uma LSTM usamos `nn.LSTM`. Observe também que a LSTM retorna um `outpit` e uma tupla do estado final `hidden` e o estado final da célula de memória.\n",
        "\n",
        "Como o estado oculto final da LSTM possui um componente direto e reverso, que são concatenados, o tamanho da entrada para a camada `nn.Linear` é o dobro do tamanho da dimensão oculta.\n",
        "\n",
        "A implementação da bidirecionalidade e a adição de camadas adicionais são feitas passando valores para os argumentos `num_layers` e` bidirectional` para o RNN/LSTM. Note que estamos usando um embedding padrão através da classe `nn.Embedding`, que recebe o tamanho do vocábulário e o tamanho do vetor de embedding como parâmetros.\n",
        "\n",
        "A regularização dropout é implementada inicializando uma camada `nn.Dropout` (o argumento é a probabilidade de dropout para cada neurônio) e usando-o dentro do método `forward` após cada camada na qual queremos aplicar o dropout. **Nota**: nunca use dropout nas camadas de entrada ou saída (`x` ou` fc` neste caso), você só deseja usar dropout em camadas intermediárias. A LSTM possui um argumento `dropout` que adiciona dropout nas conexões entre estados ocultos em uma camada e estados ocultos da próxima camada."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A18YllD-CjEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        self.fc = nn.Linear(hidden_dim*2, output_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        #x = [sent len, batch size]\n",
        "        #print(x)\n",
        "        \n",
        "        embedded = self.dropout(self.embedding(x))\n",
        "        ##print(\"embedded.size()\", embedded.size())\n",
        "        \n",
        "        #embedded = [sent len, batch size, emb dim]\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        ##print(\"hidden1.size()\", hidden.size())\n",
        "        \n",
        "        #output = [sent len, batch size, hid dim * num directions]\n",
        "        #hidden = [num layers * num directions, batch size, hid. dim]\n",
        "        #cell = [num layers * num directions, batch size, hid. dim]\n",
        "        \n",
        "        hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n",
        "        ##print(\"hidden2.size()\", hidden.size())\n",
        "                \n",
        "        #hidden [batch size, hid. dim * num directions]\n",
        "        out = self.fc(hidden.squeeze(0))\n",
        "        ##print(\"out.size()\", out.size())\n",
        "\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwqfpvBWCjEt",
        "colab_type": "text"
      },
      "source": [
        "Criaremos uma instância da classe RNN com os novos parâmetros e argumentos para o número de camadas, bidirecionalidade e probabilidade de desistência.\n",
        "\n",
        "Neste exemplo, usamos o embedding padrão do pytorch, sem pré-treinamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxyXty-MCjEt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 50 #100\n",
        "HIDDEN_DIM = 64 #256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "\n",
        "model = RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMFrE5aKCjE0",
        "colab_type": "text"
      },
      "source": [
        "### Treinado o Modelo\n",
        "\n",
        "O otimizador de `SGD` a ser usado será o ` Adam`. O SGD atualiza todos os parâmetros com a mesma taxa de aprendizado e a escolha dessa taxa de aprendizado pode ser complicada. O Adam adapta a taxa de aprendizado para cada parâmetro, fornecendo taxas de aprendizado mais baixas a parâmetros atualizados com mais frequência, e taxas de aprendizado mais altas a parâmetros atualizados com frequência mais baixa. Mais informações sobre Adam (e outros otimizadores) podem ser encontradas [aqui](http://ruder.io/optimizing-gradient-descent/index.html).\n",
        "\n",
        "Para alterar `SGD` para` Adam`, simplesmente alteramos `optim.SGD` para` optim.Adam`, observe também como não precisamos fornecer uma taxa de aprendizado inicial para Adam, pois o PyTorch especifica uma taxa de aprendizado inicial sensata."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIZ6e0uqCjE2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KZA31eRCjE5",
        "colab_type": "text"
      },
      "source": [
        "Definimos o critério e colocamos o modelo e o critério na GPU (se disponível)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ_NfQAPCjE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orbfyZDwCjE9",
        "colab_type": "text"
      },
      "source": [
        "Implementamos a função para calcular a precisão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruXQ_PWbCjE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def binary_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "\n",
        "    #round predictions to the closest integer\n",
        "    rounded_preds = torch.round(torch.sigmoid(preds))\n",
        "    correct = (rounded_preds == y).float() #convert into float for division \n",
        "    acc = correct.sum()/len(correct)\n",
        "    return acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4jJ1-_RCjFC",
        "colab_type": "text"
      },
      "source": [
        "Definimos uma função para treinar nosso modelo.\n",
        "\n",
        "**Nota**: como agora estamos usando o dropout, devemos lembrar de usar `model.train ()` para garantir que o dropout seja \"ativado\" durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifOdzhOhCjFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    print(\"Treinando ...\") ##\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.train()\n",
        "    i=0\n",
        "    \n",
        "    for batch in iterator:\n",
        "        #print(\"Texto\", batch.Texto)\n",
        "        optimizer.zero_grad()\n",
        "        i += 1\n",
        "        \n",
        "        if len(batch.Texto[0]) < 3:  ## debug\n",
        "            print(\"batch\", i, batch.Texto[0])\n",
        "            continue\n",
        "        \n",
        "        ##print(\"Texto\", batch.Texto[0])\n",
        "        src = torch.transpose(batch.Texto[0],0,1)\n",
        "        predictions = model(src)\n",
        "        ##print(predictions.size())\n",
        "        predictions=predictions.squeeze(1)\n",
        "        ##print(predictions.size())\n",
        "        \n",
        "        ##print(\"Julgamento\", batch.Julgamento)\n",
        "        loss = criterion(predictions, batch.Julgamento)\n",
        "        \n",
        "        acc = binary_accuracy(predictions, batch.Julgamento)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcvDAZRdCjFI",
        "colab_type": "text"
      },
      "source": [
        "Definimos uma função para testar nosso modelo.\n",
        "\n",
        "**Nota**: como agora estamos usando o dropout, devemos lembrar de usar `model.eval ()` para garantir que o dropout seja \"desligado\" durante a avaliação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxqbjjgoCjFJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, optimizer, criterion):\n",
        "    print(\"Avaliando ...\") ##\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    \n",
        "    model.eval()\n",
        "    i=0\n",
        "    with torch.no_grad():\n",
        "    \n",
        "        for batch in iterator:\n",
        "            i+=1\n",
        "            \n",
        "            if len(batch.Texto[0]) < 3:  ## debug\n",
        "                print(\"batch\", i, batch.Texto[0])\n",
        "                continue\n",
        "\n",
        "            src = torch.transpose(batch.Texto[0],0,1)\n",
        "        \n",
        "            predictions = model(src).squeeze(1)\n",
        "            \n",
        "            loss = criterion(predictions, batch.Julgamento)\n",
        "            \n",
        "            acc = binary_accuracy(predictions, batch.Julgamento)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            epoch_acc += acc.item()\n",
        "        \n",
        "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvycTAw5CjFL",
        "colab_type": "text"
      },
      "source": [
        "Finalmente, treinamos nosso modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3U6e2SYCjFN",
        "colab_type": "code",
        "outputId": "7b35dcc4-dad4-4a6b-9f31-11aba89e3765",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "N_EPOCHS = 5\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(\"Starting Epoch:\", epoch+1)\n",
        "  \n",
        "    train_loss, train_acc = train(model, trainIter, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, validIter, optimizer, criterion)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Train Acc: {train_acc*100:.2f}%, Val. Loss: {valid_loss:3f}, Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting Epoch: 1\n",
            "Treinando ...\n",
            "batch 1001 tensor([[  2,  13,  19,  10,   4, 138,   8,   6, 412,  12,  34,  81,  28,  21,\n",
            "           4,   3]], device='cuda:0')\n",
            "Avaliando ...\n",
            "Epoch: 01, Train Loss: 0.427, Train Acc: 79.62%, Val. Loss: 0.341282, Val. Acc: 84.46%\n",
            "Starting Epoch: 2\n",
            "Treinando ...\n",
            "batch 1001 tensor([[  2, 107, 370,   6,  12,  36, 267,   5, 175, 207,   5,   7,  14,  33,\n",
            "          92, 133,   4,   3]], device='cuda:0')\n",
            "Avaliando ...\n",
            "Epoch: 02, Train Loss: 0.340, Train Acc: 85.18%, Val. Loss: 0.299502, Val. Acc: 87.36%\n",
            "Starting Epoch: 3\n",
            "Treinando ...\n",
            "batch 1001 tensor([[  2, 115,  40,   0,   5,  14,  18,  10,  13,  19,   5,   7, 115, 656,\n",
            "          17,  35, 406,   3]], device='cuda:0')\n",
            "Avaliando ...\n",
            "Epoch: 03, Train Loss: 0.308, Train Acc: 86.63%, Val. Loss: 0.277161, Val. Acc: 88.77%\n",
            "Starting Epoch: 4\n",
            "Treinando ...\n",
            "batch 1001 tensor([[  2, 747,  18, 315, 398,   0, 107, 524,  15, 330,  29,  59, 206,   4,\n",
            "          10,   0,   4,   3]], device='cuda:0')\n",
            "Avaliando ...\n",
            "Epoch: 04, Train Loss: 0.293, Train Acc: 87.35%, Val. Loss: 0.260740, Val. Acc: 90.19%\n",
            "Starting Epoch: 5\n",
            "Treinando ...\n",
            "batch 1001 tensor([[  2,   0,   0,  17,   8, 623,   5,  29,  11, 572, 245,   4,   3]],\n",
            "       device='cuda:0')\n",
            "Avaliando ...\n",
            "Epoch: 05, Train Loss: 0.271, Train Acc: 88.56%, Val. Loss: 0.249810, Val. Acc: 89.79%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVr9cvANCjFQ",
        "colab_type": "text"
      },
      "source": [
        "Testamos a acurácia em dados nunca vistos durante o treinamento."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QS6sgJLTCjFR",
        "colab_type": "code",
        "outputId": "f909ece0-a291-4f8c-8763-ba31fee77135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_loss, test_acc = evaluate(model, testIter, optimizer, criterion)\n",
        "\n",
        "print(f'Test Loss: {test_loss:.3f}, Test Acc: {test_acc*100:.2f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avaliando ...\n",
            "Test Loss: 0.238, Test Acc: 89.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCjoKDS4CjFX",
        "colab_type": "text"
      },
      "source": [
        "### Entrada do usuário\n",
        "\n",
        "Agora podemos usar nosso modelo para prever o sentimento de qualquer sentença que damos a ele. Como foi treinado em resenhas de produtos, as frases fornecidas também devem ser resenhas de produtos.\n",
        "\n",
        "Nossa função `predict_sentiment` faz algumas coisas:\n",
        "- tokeniza a frase, ou seja, divide-a de uma sequência bruta em uma lista de tokens\n",
        "- indexa os tokens convertendo-os em sua representação inteira do nosso vocabulário\n",
        "- converte os índices, que são uma lista Python em um tensor PyTorch\n",
        "- adicione uma dimensão de lote ao cancelar a seleção\n",
        "- esmaga a previsão de saída de um número real entre 0 e 1 com a função `sigmoid`\n",
        "- converte o tensor segurando um único valor em um inteiro com o método `item ()`\n",
        "\n",
        "Esperamos que revisões com um sentimento negativo retornem um valor próximo de 0 e revisões positivas que retornem um valor próximo de 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0htQ2RPCjFY",
        "colab_type": "code",
        "outputId": "d4adba3a-ac84-4231-d6b8-9f0fc18987b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def predict_sentiment(sentence):\n",
        "    tokenized = tokenizePT(sentence)\n",
        "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
        "    tensor = torch.LongTensor(indexed).to(device)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    pred = model(tensor)\n",
        "    prediction = torch.sigmoid(pred)\n",
        "    return prediction.item()\n",
        "\n",
        "print(predict_sentiment(\"Essa droga não serve para nada\")) \n",
        "\n",
        "print(predict_sentiment(\"Esse produto é maravilhoso!!!\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2131531834602356\n",
            "0.9384145736694336\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}