{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras Introduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGHhgFL57Knw",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder\n",
        "---\n",
        "Autoencoder are neural networks composed of two parts: The encoder and decoder.\n",
        "The encoder takes the input and compress it to a latent vector z. The decoder takes the latent as input and try to reconstruct the input data. \n",
        "\n",
        "The network is trained to reconstruct the input data through the bottleneck created by the encoder-decoder.\n",
        "We are going to create an autoencoder with Keras framework\n",
        "\n",
        "Keras framework.\n",
        "---\n",
        "Keras is a framework to help create deep neural networks easily and efficiently. \n",
        "To create a neural network in Keras is needed to define:\n",
        "The layers of the network, \n",
        "1. Create the Model.\n",
        "2. Load the dataset.\n",
        "3. Train the network.\n",
        "4. Make the Prediction\n",
        "\n",
        "Import the Keras Framework\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lclA1ywL7AyH",
        "colab_type": "code",
        "outputId": "56ad326f-1767-4636-f078-76bf4572bf47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "%tensorflow_version 1.x  # This is to allow tensorflow v1 with keras.\n",
        "import keras.backend as K #Import the keras backend that contains basic operations such as Cos, Exp, Log and so on.\n",
        "from keras.models import Model, Sequential # it will be used to create the models (encoder, decoder, Autoencoder).\n",
        "from keras.layers import Dense, Input # it imports the layer(s) to be used in the contruction.\n",
        "from keras.losses import mean_squared_error, binary_crossentropy # loss function to be optimized.\n",
        "from keras.optimizers import SGD, RMSprop, Adam # optimization algorithm.\n",
        "from keras.datasets import mnist, fashion_mnist # Datasets to be used in the experiments.\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt # Plot and show stuff\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
            "You set: `1.x  # This is to allow tensorflow v1 with keras.`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFMtj8wQBFYp",
        "colab_type": "text"
      },
      "source": [
        "Model of the Encoder\n",
        "---\n",
        "The encoder will be composed of  Dense Layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQn1uO63BdYe",
        "colab_type": "code",
        "outputId": "c3003003-69e2-4976-b445-a0d1919e07e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "\n",
        "latent_dim = 10 #latent dimension\n",
        "\n",
        "encoder = Sequential(name=\"encoder\") # Instanciate the encoder model\n",
        "encoder.add(Dense(128, input_shape=(784,), activation=\"relu\")) # first dense layer with input shape 784 = 28*28\n",
        " # You can add more layers if you want here.\n",
        "encoder.add(Dense(latent_dim)) # Latent vector.\n",
        "encoder.summary() # shows the structure of networks.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXxqQfWBKxSd",
        "colab_type": "text"
      },
      "source": [
        "Model of the Decoder\n",
        "---\n",
        "The Decoder will be composed of \n",
        " Dense Layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve_f10NpLRCb",
        "colab_type": "code",
        "outputId": "99b29437-a450-4172-e037-0e5c914d6403",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "source": [
        "decoder =  Sequential(name=\"decoder\")\n",
        "\n",
        "decoder.add(Dense(128, activation=\"relu\", input_shape=(latent_dim,) )) # Input of the autoencoder with the latent dimension\n",
        " # You can add more layers if you want here.\n",
        "decoder.add(Dense(784, activation=\"sigmoid\")) # Output of the decoder with shape 784 = 28*28.\n",
        "decoder.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 128)               1408      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 784)               101136    \n",
            "=================================================================\n",
            "Total params: 102,544\n",
            "Trainable params: 102,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSYqpe79MoT6",
        "colab_type": "text"
      },
      "source": [
        "Autoencoder Model\n",
        "---\n",
        "The autoencoder combines the encoder and decoder models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nznS7h35NG3U",
        "colab_type": "code",
        "outputId": "c707a8de-feaf-4b51-eeeb-291f7579ea19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "source": [
        "input_img = Input(shape=(784,) ) # Defines the Input of the AE. 784 =28*28\n",
        "z = encoder(input_img) # It obtains the latent vector from input image using the encoder.\n",
        "recons = decoder(z) # it tries to reconstruct the input image from the input image.\n",
        "ae = Model(input_img, recons) # Creates the AE model using the input of encoder (input_img) and output of decoder (recons).\n",
        "ae.summary() # Show the model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "encoder (Sequential)         (None, 10)                101770    \n",
            "_________________________________________________________________\n",
            "decoder (Sequential)         (None, 784)               102544    \n",
            "=================================================================\n",
            "Total params: 204,314\n",
            "Trainable params: 204,314\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdUayf5TO3Mu",
        "colab_type": "text"
      },
      "source": [
        "Loss Function\n",
        "---\n",
        "After the model is defined, we need to compile the model, defining what is the loss function and the optimization algorithm to be used during the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c7EVT7PQIVF",
        "colab_type": "code",
        "outputId": "cd4703ca-959a-4e68-ceec-5d2a1f14b675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "opt = RMSprop(lr=1e-3) #Instanciates the optimizer setting the learning rate.\n",
        "ae.compile(optimizer=opt, loss=mean_squared_error, metrics=[\"mean_squared_error\"]) # compiles the model defining the optimization algorithm, loss function and metrics."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLt2ZyV8RYdi",
        "colab_type": "text"
      },
      "source": [
        "Datasets\n",
        "---\n",
        "We need to load the dataset. Often, the datasets are loaded from files. In such situation we should use Dataloader avaliable in Keras framework or use other means.\n",
        "In our case, the dataset MNIST and MNIST fashion can be loaded using Keras API.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXjw0daLR_oo",
        "colab_type": "code",
        "outputId": "ed0b3ffa-2672-4b68-df42-deb1d51ca119",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "(x_train,y_train), (x_test,y_test) =  mnist.load_data() # Load mnist digits images and labels for train (x_train, y_train) and test (x_test, y_test).\n",
        "# x_train is a tensor with 60.000 28x28 digits images for training.\n",
        "# y_train is an array with labels for each images in train dataset.\n",
        "\n",
        "# x_test is a tensor with 10.000 28x28 digits images for testing.\n",
        "# y_test is an array with labels for each images in test set.\n",
        "\n",
        "image = x_train[1040] # get the an image\n",
        "\n",
        "plt.imshow(image) # show the digit just for curiosity.\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhB0IgrADQfw/MgaLVOEp/QEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GOHDJfVT_RY",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the Dataset\n",
        "---\n",
        "1. The image if composed of pixels with values in the range [0-255]. It is a good practice to normalize the dataset to stay in the range [0-1].\n",
        "\n",
        "2. Our AE is made of Dense layers. In such situation we need to flatten the image from (28,28) to 784 allowing to feed the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V55dw_XrVD_H",
        "colab_type": "code",
        "outputId": "cf19f6b6-99fd-4100-ce65-fe8a20ae59dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train = (x_train/255.0).astype(np.float32) # normalize the image and convert it to float.\n",
        "x_test = (x_test/255.0).astype(np.float32) # normalize the image and convert it to float.\n",
        "\n",
        "x_train = np.reshape(x_train, (-1, 784)) # Reshape the tensor to convert from the shape [60000, 28,28] => [60000, 784]\n",
        "x_test = np.reshape(x_test, (-1, 784)) # Reshape the tensor to convert from the shape [10000, 28,28] => [10000, 784]\n",
        "print(x_train[0]) #just for curiosity display the contat of a flatten image.\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.01176471 0.07058824 0.07058824 0.07058824\n",
            " 0.49411765 0.53333336 0.6862745  0.10196079 0.6509804  1.\n",
            " 0.96862745 0.49803922 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.11764706 0.14117648 0.36862746 0.6039216\n",
            " 0.6666667  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.88235295 0.6745098  0.99215686 0.9490196  0.7647059  0.2509804\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.19215687\n",
            " 0.93333334 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.9843137  0.3647059  0.32156864\n",
            " 0.32156864 0.21960784 0.15294118 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.07058824 0.85882354 0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.99215686 0.7764706  0.7137255\n",
            " 0.96862745 0.94509804 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.3137255  0.6117647  0.41960785 0.99215686\n",
            " 0.99215686 0.8039216  0.04313726 0.         0.16862746 0.6039216\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.05490196 0.00392157 0.6039216  0.99215686 0.3529412\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.54509807 0.99215686 0.74509805 0.00784314 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.04313726\n",
            " 0.74509805 0.99215686 0.27450982 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.13725491 0.94509804\n",
            " 0.88235295 0.627451   0.42352942 0.00392157 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.31764707 0.9411765  0.99215686\n",
            " 0.99215686 0.46666667 0.09803922 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.1764706  0.7294118  0.99215686 0.99215686\n",
            " 0.5882353  0.10588235 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.0627451  0.3647059  0.9882353  0.99215686 0.73333335\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.9764706  0.99215686 0.9764706  0.2509804  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.18039216 0.50980395 0.7176471  0.99215686\n",
            " 0.99215686 0.8117647  0.00784314 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.15294118 0.5803922\n",
            " 0.8980392  0.99215686 0.99215686 0.99215686 0.98039216 0.7137255\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.09411765 0.44705883 0.8666667  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.7882353  0.30588236 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09019608 0.25882354 0.8352941  0.99215686\n",
            " 0.99215686 0.99215686 0.99215686 0.7764706  0.31764707 0.00784314\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.07058824 0.67058825\n",
            " 0.85882354 0.99215686 0.99215686 0.99215686 0.99215686 0.7647059\n",
            " 0.3137255  0.03529412 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.21568628 0.6745098  0.8862745  0.99215686 0.99215686 0.99215686\n",
            " 0.99215686 0.95686275 0.52156866 0.04313726 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.53333336 0.99215686\n",
            " 0.99215686 0.99215686 0.83137256 0.5294118  0.5176471  0.0627451\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSczqeXJWODj",
        "colab_type": "text"
      },
      "source": [
        "Train the Network\n",
        "---\n",
        "With the data, we can train the autoencoder using the method fit of the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAQk-ZqmWXX7",
        "colab_type": "code",
        "outputId": "8386bbd6-0df1-4434-8f9b-f9a52332a1dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 688
        }
      },
      "source": [
        "\n",
        "batch_size = 128\n",
        "epochs = 10\n",
        "ae.fit(x_train, x_train, batch_size=batch_size, epochs = epochs, validation_data=(x_test,x_test), verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "60000/60000 [==============================] - 5s 80us/step - loss: 0.0401 - mean_squared_error: 0.0401 - val_loss: 0.0277 - val_mean_squared_error: 0.0277\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0261 - mean_squared_error: 0.0261 - val_loss: 0.0238 - val_mean_squared_error: 0.0238\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0236 - mean_squared_error: 0.0236 - val_loss: 0.0225 - val_mean_squared_error: 0.0225\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0216 - val_mean_squared_error: 0.0216\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0207 - val_mean_squared_error: 0.0207\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0208 - mean_squared_error: 0.0208 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 66us/step - loss: 0.0203 - mean_squared_error: 0.0203 - val_loss: 0.0200 - val_mean_squared_error: 0.0200\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 67us/step - loss: 0.0200 - mean_squared_error: 0.0200 - val_loss: 0.0195 - val_mean_squared_error: 0.0195\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0197 - val_mean_squared_error: 0.0197\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 68us/step - loss: 0.0198 - mean_squared_error: 0.0198 - val_loss: 0.0205 - val_mean_squared_error: 0.0205\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff0e7be6c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh65JphtXni0",
        "colab_type": "text"
      },
      "source": [
        "Seeing the Recontruction\n",
        "---\n",
        "After trained the encoder, decoder and AE can be used to extract feature, produce image and reconstruct. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhyCzigNXy-E",
        "colab_type": "code",
        "outputId": "cfc0fe10-1790-4335-cbe1-fed1f5582574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "img = x_test[888] # get an image from the test dataset\n",
        "imgb = np.reshape(img, (1, 784)) # reshape to have shape [1, 785]\n",
        "recons_img = ae.predict( imgb ) # feed the AE and get outputs.\n",
        "\n",
        "recons_img = np.reshape(recons_img, (28,28)) # reshape the predition to (28, 28)\n",
        "\n",
        "print(\"Original Image\")\n",
        "\n",
        "img_original = np.reshape(img, (28,28)) # reshape from flatten to squared image.\n",
        "\n",
        "plt.imshow(img_original)\n",
        "plt.show()\n",
        "print(\"Reconstructed Image\")\n",
        "plt.imshow(recons_img)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original Image\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Reconstructed Image\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HFSarHXeAmk",
        "colab_type": "text"
      },
      "source": [
        "Tasks\n",
        "---\n",
        "1. Change the Optimizer from RMSProp to Adam. Is there some difference?\n",
        "2. Change cross_entropy loss for mean_squared_error. What are the difference in aspect of the reconstructed image?\n",
        "3. Add a Dense layer in the encoder and decoder with 256 neurons. What is the behavior of the loss during the training?\n"
      ]
    }
  ]
}