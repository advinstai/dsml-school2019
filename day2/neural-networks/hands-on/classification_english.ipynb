{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "classification-english.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "wiAl8lfp8gyN",
        "8CNAZ4xABI4S",
        "xgT1WrhrDErp"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aB42jddnJNcC",
        "colab_type": "text"
      },
      "source": [
        "https://www.dropbox.com/s/py7m9jsfquhb6w4/Photo%2006.04.15%2000%2024%2020.png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6BdW5jux5Uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfetAMOZprZc",
        "colab_type": "text"
      },
      "source": [
        "# A classification problem\n",
        "Breast Cancer Wisconsin Diagnostic Database. The dataset includes information about breast cancer tumors, as well as classification labels: malignant or benign (self-note: pronunciation [bɪˈnaɪn]). There are 569 instances, including information on 30 attributes (or characteristics, features...) such as tumor radius, texture, smoothness, and area.\n",
        "\n",
        "We will build a machine learning model to use tumor information to predict whether it is malignant or benign.\n",
        "\n",
        "The first step is to import **sklearn** and the dataset **breast_cancer**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjvivpC3prZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "print(load_breast_cancer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEOvLj6Hy4Lp",
        "colab_type": "text"
      },
      "source": [
        "Load the dataset into the *data* variable and split different types of information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6aGVsC2prZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = load_breast_cancer()\n",
        "\n",
        "classes = data['target_names']\n",
        "labels = data['target']\n",
        "\n",
        "attributes = data['feature_names']\n",
        "instances = data['data']\n",
        "\n",
        "len(instances)\n",
        "print(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAMEuEfkPUb-",
        "colab_type": "text"
      },
      "source": [
        "The class names are malignant and benign, which are then mapped to binary values (0 or 1). Our goal is to be able to diagnose patients according to tumor characteristics.\n",
        "\n",
        "This type of classification is possible when a learning algorithm induces a model based on the relationships between labels and attributes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8uOEfRqOAPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(classes) # only names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4XD0LCiOIN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels[10:30] # y: only values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHwUsLCKQUiQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(labels) / len(labels) # out of curiosity..."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ95MyXZOMgT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(attributes) # only names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDFXoHc0OTJF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(instances[2:4]) # X: only values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGuZ67EB0hOO",
        "colab_type": "text"
      },
      "source": [
        "To evaluate the performance of a classifier, we must always test the model on unlabeled, new individuals, i.e. those whose classes are unknown to the induced model.\n",
        "\n",
        "Data should be divided into two parts to simulate the existence of new individuals before constructing a model: training and testing sets.\n",
        "\n",
        "We use the training set to train and evaluate/select a model during the development stage. *More on this later*.\n",
        "\n",
        "Then we use the induced (trained) model to make predictions in the testing set. This approach gives us an estimation of model generalization performance and robustness.\n",
        "\n",
        "The train_test_split function helps us with this task. For now, we will experiment using directly the testing data for simplicity, but at the end we will simulate a more realistic training/evaluation/selection/testing workflow.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-T5MgmJS2f4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test, train_labels, test_labels = train_test_split(instances,\n",
        "                                                          labels,\n",
        "                                                          test_size=0.33,\n",
        "                                                          random_state=42)\n",
        "print('# training instances', len(train))\n",
        "print('# testing instances', len(test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbzPmpwx29h6",
        "colab_type": "text"
      },
      "source": [
        "We now have a testing set that represents 33% of the original dataset.\n",
        "The remaining data (train) forms the training data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK3OFbDW3G2l",
        "colab_type": "text"
      },
      "source": [
        "There are many algorithms for machine learning, and each of them has strengths and weaknesses (*learning bias*, complexity, interpretability, ...).\n",
        "\n",
        "A simple and fast classification algorithm is Naive Bayes (NB).\n",
        "\n",
        "Let's import the GaussianNB module and induce the model with the fit () method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOdT-uoX3j4J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(train, train_labels)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSzV775I3qcA",
        "colab_type": "text"
      },
      "source": [
        "We can use the induced model to make predictions in our testing set using the predict () function.\n",
        "The predict () function returns an array of predicted labels for each data instance in the testing set. We can then print out the predictions to get an idea of what the model has to say about the health of individuals in the testing set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giENWzmE4BiW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = gnb.predict(test)\n",
        "print(preds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC9r_JPIUwT_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(preds) / len(test), sum(preds) # out of curiosity..., what is the prevalence of healthy individuals in prediction?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k2xUoFLVY8x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(test_labels) / len(test), sum(test_labels) # out of curiosity..., what is the prevalence of healthy individuals in reality?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03XMTPdSWxVJ",
        "colab_type": "text"
      },
      "source": [
        "It seems that at least one person could have died should we rely on Naive Bayes. Let's check how many false negatives are there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIcGeMHrXsek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "false_negatives = (1 - test_labels) * preds\n",
        "sum(false_negatives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W85Gw8YwjMCJ",
        "colab_type": "text"
      },
      "source": [
        "Actually, 6 people should not trust in Naive Bayes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtOVlQ8xiKvm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "false_positives = test_labels * (1 - preds)\n",
        "sum(false_positives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqXAYSq57OcQ",
        "colab_type": "text"
      },
      "source": [
        "And 5 people probably would be needlessly worried and screened again in more accurate/expensive laboratory tests.\n",
        "\n",
        "We could also evaluate the accuracy of the predicted values of our model by using sklearn's accuracy_score() function. However it doesn't take into account the different types of errors. Precision, recall, f-score and other measures can do a better job in medical areas (and are included in sklearn). We will stick with the 'miss rate' here for simplicity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2lzfsaH7Zek",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(test_labels, preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12Ae8kdFgCbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sum(false_negatives) / sum(1 - test_labels) # miss rate [ERRATA: it was 'preds' in denominator]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiAl8lfp8gyN",
        "colab_type": "text"
      },
      "source": [
        "# Cross validation\n",
        "For a better estimatation, and given the small number of examples (569), we can use cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkmnIUUL9CEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(gnb, train, train_labels, cv=10)\n",
        "scores"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoVnYkDpAB_G",
        "colab_type": "text"
      },
      "source": [
        "Considering a confidence interval of 95% (p-value=0.05)..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zwclz3hAK1E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2 / numpy.sqrt(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxhCrx5bA32Y",
        "colab_type": "text"
      },
      "source": [
        "...95 times out of a hundred attempts the accuracy will be between 0.91 and 0.97 (according to https://www.mathsisfun.com/data/confidence-interval.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CNAZ4xABI4S",
        "colab_type": "text"
      },
      "source": [
        "# Neural network\n",
        "\n",
        "How well would a neural network perform? Hopefully, nothing *deep* needed here... "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvheEP8AsDRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning excess of output regarding MLP convergence\n",
        "import warnings, os\n",
        "warnings.simplefilter(\"ignore\")\n",
        "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier as MLP\n",
        "\n",
        "mlp = MLP()\n",
        "model = mlp.fit(train, train_labels)\n",
        "model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DRh0nh7AhvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds = mlp.predict(test)\n",
        "false_negatives = (1 - test_labels) * preds\n",
        "sum(false_negatives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlVba9KUtP2g",
        "colab_type": "text"
      },
      "source": [
        "2 less people at risk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_HR5lTEtT6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "false_positives = test_labels * (1 - preds)\n",
        "sum(false_positives)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5doH-NVuteUk",
        "colab_type": "text"
      },
      "source": [
        "3 less worried people. However, the cross-validated accuracy is \"worse\" (0.93 < 0.94). How is that possible?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dNb3TGtRLoe0",
        "colab": {}
      },
      "source": [
        "scores = cross_val_score(mlp, train, train_labels, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2 / numpy.sqrt(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wy8q1SJMvpJt",
        "colab_type": "text"
      },
      "source": [
        "We can implement our own score function to cross-validate. Function fn, or 'number of false negatives'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIR8kYKRvw6F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import make_scorer\n",
        "def fn(y_true, y_pred): return sum((1 - y_true) * y_pred)\n",
        "scoring = make_scorer(fn)\n",
        "scoring"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1lOp13xwkGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scores = cross_val_score(mlp, train, train_labels, cv=10, scoring=scoring)\n",
        "print(\"FN: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2 / numpy.sqrt(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9XAM1r91cFt",
        "colab_type": "text"
      },
      "source": [
        "Trying to improve it, taking advantage of probability predictions (without cross-validation for simplicity)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biQsSbCH1kKi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "probs = mlp.predict_proba(test)[:,1] # taking second column, since there the value 1 means class 1 (fst col = 1 - snd col)\n",
        "print(probs[:6])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUoodxxFCoc9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rectify(threshold): return lambda predictions: [0 if x < threshold else 1 for x in predictions]\n",
        "rectify(0.5)(probs[:6])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvf4DZf0GsVO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.5)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KQ1pF7wHr3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.9)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UytLqGweHwBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.99)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GztfDQQHIoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.999)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdwgkn7eIVFL",
        "colab_type": "text"
      },
      "source": [
        "Only malignant tumors predicted. Going in the opposite direction..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iYQSU8OGENNq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.5)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfyN6nAvHX4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.1)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koJbzu5oF-r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.01)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Adq5zf0vH2Ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.001)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aSX7j-gOQ3i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rectify(0.000001)(probs[:20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oTCGxHNHBR1",
        "colab_type": "text"
      },
      "source": [
        "It seems like MLP refuses to consider all tumors benign. Some patients are lucky in the sense of being correctly diagnosed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjVt4-TGIsly",
        "colab_type": "text"
      },
      "source": [
        "As long as the threshold has some effect on predictions, we can calibrate it to avoid leaving patients undiagnosed, at the expense of the healthy ones that will have to make useless additional tests."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x28fQrWCkUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calibrated_preds = rectify(0.5)(probs)\n",
        "false_negatives = (1 - test_labels) * calibrated_preds\n",
        "false_positives = test_labels * (1 - numpy.array(calibrated_preds))\n",
        "print('usual threshold... undiagnosed:', sum(false_negatives), '     wasting additional tests:', sum(false_positives))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOwevLIEJwnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calibrated_preds = rectify(0.6)(probs)\n",
        "false_negatives = (1 - test_labels) * calibrated_preds\n",
        "false_positives = test_labels * (1 - numpy.array(calibrated_preds))\n",
        "print('usual threshold... undiagnosed:', sum(false_negatives), '     wasting additional tests:', sum(false_positives))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji8vu-5fQ34Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calibrated_preds = rectify(0.7)(probs)\n",
        "false_negatives = (1 - test_labels) * calibrated_preds\n",
        "false_positives = test_labels * (1 - numpy.array(calibrated_preds))\n",
        "print('usual threshold... undiagnosed:', sum(false_negatives), '     wasting additional tests:', sum(false_positives))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-haOskc4REgx",
        "colab_type": "text"
      },
      "source": [
        "Losing money, but saving lives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqXy1pldJoc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calibrated_preds = rectify(0.4)(probs) # Out of curiosity...\n",
        "false_negatives = (1 - test_labels) * calibrated_preds\n",
        "false_positives = test_labels * (1 - numpy.array(calibrated_preds))\n",
        "print('usual threshold... undiagnosed:', sum(false_negatives), '     wasting additional tests:', sum(false_positives))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WglGb53hRdci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "calibrated_preds = rectify(0.3)(probs)\n",
        "false_negatives = (1 - test_labels) * calibrated_preds\n",
        "false_positives = test_labels * (1 - numpy.array(calibrated_preds))\n",
        "print('usual threshold... undiagnosed:', sum(false_negatives), '     wasting additional tests:', sum(false_positives))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25sIDRreRikS",
        "colab_type": "text"
      },
      "source": [
        "Saving money (high *precision*), but losing lives (*\\\"low\\\" recall*).\n",
        "\n",
        "See more here:\n",
        "https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgT1WrhrDErp",
        "colab_type": "text"
      },
      "source": [
        "# A harder non medical problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vT3dlL9mEjPR",
        "colab_type": "text"
      },
      "source": [
        "Vegetal cover type/satellite data. Undersampled due to time/hardware restrictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvnOSlZeDlSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import covtype\n",
        "data = covtype.fetch_covtype()\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "cc = RandomUnderSampler(random_state=42)\n",
        "dados, rótulos = cc.fit_resample(data['data'], data['target'])\n",
        "train, test, train_labels, test_labels = train_test_split(dados,\n",
        "                                                          rótulos,\n",
        "                                                          test_size=0.33,\n",
        "                                                          random_state=42)\n",
        "len(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rZYO7cREt6Q",
        "colab_type": "text"
      },
      "source": [
        "Estimation for several classifiers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PBYfXiBLDgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = MLP()\n",
        "scores = cross_val_score(mlp, train, train_labels, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2 / numpy.sqrt(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE1SM5C-HwqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "scores = cross_val_score(gnb, train, train_labels, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2 / numpy.sqrt(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfe-n29LK_ij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neighbors.classification import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier(n_neighbors = 5)\n",
        "scores = cross_val_score(knn, train, train_labels, cv=10)\n",
        "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2 / numpy.sqrt(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DaZ36-fEz12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators = 100, random_state = 42)\n",
        "scores = cross_val_score(rf, train, train_labels, cv=10)\n",
        "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2 / numpy.sqrt(len(scores))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "spdMt-1AMqvJ",
        "colab_type": "text"
      },
      "source": [
        "Now that we have chosen an algorithm, does it generalize with the same accuracy on unseen data? 0.003 st. dev. suggests low variability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLj0FgyINY5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_model = rf.fit(train, train_labels)\n",
        "preds = real_model.predict(test)\n",
        "print(accuracy_score(test_labels, preds))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqiZpdm5DnMs",
        "colab_type": "text"
      },
      "source": [
        "Indeed, the generalization accuracy is not far from the model selection accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIxUnVrZgeBT",
        "colab_type": "text"
      },
      "source": [
        "Based on:\n",
        "\n",
        "https://www.digitalocean.com/community/tutorials/como-construir-um-classificador-de-machine-learning-em-python-com-scikit-learn-pt\n"
      ]
    }
  ]
}